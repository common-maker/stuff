{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjfUGYfQmdws"
      },
      "source": [
        "# ALASKA2 Image Steganalysis\n",
        "### Detecting Hidden Data in Images Using Deep Learning\n",
        "CQ 2021/21  \n",
        "Nguyễn Văn Hậu  - 21120449 \n",
        "Nguyễn Đức Minh Quân - 20120357\n",
        "\n",
        "**Project Objective:**\n",
        "The project is based on the ALASKA2 Image Steganalysis competition on Kaggle, which requires teams to create algorithms capable of efficiently detecting hidden data.  \n",
        "## 1. Problem Statement\n",
        "### 1.1. Steganalysis Problem  \n",
        "Steganography is a technique that hides information within digital media (images, audio, video) to conceal secret messages without significantly altering the original data. In contrast, steganalysis aims to detect and decode this hidden information.\n",
        "\n",
        "In this problem, we will work with a dataset containing images from various sources (50 different cameras). Some of these images contain hidden messages, while others do not. The goal is to develop a model that can accurately identify which images contain hidden data.\n",
        "\n",
        "### 1.2. Challenges\n",
        "Steganographic techniques are advanced.  \n",
        "Images come from different cameras, adding variability to the dataset.  \n",
        "Finding the right features for detection is complex, as small pixel changes are hard to spot.  \n",
        "### 1.3. Approach\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "| Week                | work                                                                 |\n",
        "|---------------------|------------------------------------------------------------------------|\n",
        "| Week 01 (17/3 - 23/3)  | Research steganography, collect papers, explore ALASKA2 dataset      |\n",
        "| Week 02 - 03 (24/3 - 06/4) | Preprocess dataset, analyze image distributions, extract features |\n",
        "| Week 04 - 05 (07/4 - 20/4) | Extract deep learning features, experiment with different preprocessing techniques |\n",
        "| Week 06 - 07 (21/4 - 04/5) | Train models, optimize hyperparameters, evaluate different approaches |\n",
        "| Week 08 (05/5 - 11/5)  | Submit initial results to Kaggle, evaluate performance              |\n",
        "| Week 09 - 10 (12/5 - 25/5) | - Improve accuracy with ensemble learning <br> - Prepare presentation, submit final report |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'pandas'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m BASE_PATH = \u001b[33m\"\u001b[39m\u001b[33m/alaska2-image-steganalysis\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m train_imageids = pd.Series(os.listdir(BASE_PATH + \u001b[33m'\u001b[39m\u001b[33m/Cover\u001b[39m\u001b[33m'\u001b[39m)).sort_values(ascending=\u001b[38;5;28;01mTrue\u001b[39;00m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "BASE_PATH = \"/alaska2-image-steganalysis\"\n",
        "train_imageids = pd.Series(os.listdir(BASE_PATH + '/Cover')).sort_values(ascending=True).reset_index(drop=True)\n",
        "test_imageids = pd.Series(os.listdir(BASE_PATH + '/Test')).sort_values(ascending=True).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'numpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[34;01mplt\u001b[39;00m\n",
            "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "from tqdm.notebook import tqdm\n",
        "import random\n",
        "from PIL import Image\n",
        "import PIL.ExifTags\n",
        "from collections import Counter\n",
        "import glob\n",
        "import math\n",
        "from scipy.stats import ks_2samp\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Define paths\n",
        "KAGGLE_PATH = '/alaska2-image-steganalysis/'\n",
        "TRAIN_PATH = os.path.join(KAGGLE_PATH, 'train')\n",
        "TEST_PATH = os.path.join(KAGGLE_PATH, 'test')\n",
        "SAMPLE_SUBMISSION = os.path.join(KAGGLE_PATH, 'sample_submission.csv')\n",
        "\n",
        "# 1. Basic Dataset Information\n",
        "print(\"=== ALASKA2 Image Steganalysis Dataset ===\")\n",
        "\n",
        "# Get list of all train images\n",
        "all_train_imgs = glob.glob(os.path.join(TRAIN_PATH, \"*.jpg\"))\n",
        "print(f\"Total training images: {len(all_train_imgs)}\")\n",
        "\n",
        "# Identify cover images and stego categories\n",
        "cover_imgs = [img for img in all_train_imgs if os.path.basename(img).startswith(\"Cover\")]\n",
        "jmipod_imgs = [img for img in all_train_imgs if os.path.basename(img).startswith(\"JMiPOD\")]\n",
        "juniward_imgs = [img for img in all_train_imgs if os.path.basename(img).startswith(\"JUNIWARD\")]\n",
        "uerd_imgs = [img for img in all_train_imgs if os.path.basename(img).startswith(\"UERD\")]\n",
        "\n",
        "print(f\"Cover (clean) images: {len(cover_imgs)}\")\n",
        "print(f\"JMiPOD stego images: {len(jmipod_imgs)}\")\n",
        "print(f\"JUNIWARD stego images: {len(juniward_imgs)}\")\n",
        "print(f\"UERD stego images: {len(uerd_imgs)}\")\n",
        "\n",
        "# Get list of test images\n",
        "test_imgs = glob.glob(os.path.join(TEST_PATH, \"*.jpg\"))\n",
        "print(f\"Test images: {len(test_imgs)}\")\n",
        "\n",
        "# Class distribution\n",
        "class_distribution = {\n",
        "    'Cover': len(cover_imgs),\n",
        "    'JMiPOD': len(jmipod_imgs),\n",
        "    'JUNIWARD': len(juniward_imgs),\n",
        "    'UERD': len(uerd_imgs)\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(x=list(class_distribution.keys()), y=list(class_distribution.values()))\n",
        "plt.title('Class Distribution in Training Set')\n",
        "plt.ylabel('Number of Images')\n",
        "plt.xlabel('Image Type')\n",
        "for i, v in enumerate(class_distribution.values()):\n",
        "    plt.text(i, v + 100, str(v), ha='center')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Image Dimensions Analysis\n",
        "print(\"\\n=== Image Dimensions Analysis ===\")\n",
        "\n",
        "def get_image_dimensions(img_path):\n",
        "    \"\"\"Get image dimensions (width, height)\"\"\"\n",
        "    img = Image.open(img_path)\n",
        "    return img.size\n",
        "\n",
        "# Sample a subset of images for dimension analysis\n",
        "sample_size = min(1000, len(all_train_imgs))\n",
        "sampled_imgs = random.sample(all_train_imgs, sample_size)\n",
        "\n",
        "dimensions = [get_image_dimensions(img) for img in tqdm(sampled_imgs, desc=\"Getting image dimensions\")]\n",
        "widths, heights = zip(*dimensions)\n",
        "\n",
        "print(f\"Width statistics: Min={min(widths)}, Max={max(widths)}, Mean={np.mean(widths):.2f}, Median={np.median(widths)}\")\n",
        "print(f\"Height statistics: Min={min(heights)}, Max={max(heights)}, Mean={np.mean(heights):.2f}, Median={np.median(heights)}\")\n",
        "\n",
        "# Plot dimension distribution\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.hist(widths, bins=20, alpha=0.7)\n",
        "plt.title('Distribution of Image Widths')\n",
        "plt.xlabel('Width (pixels)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.hist(heights, bins=20, alpha=0.7)\n",
        "plt.title('Distribution of Image Heights')\n",
        "plt.xlabel('Height (pixels)')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Scatter plot of width vs height\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.scatter(widths, heights, alpha=0.5)\n",
        "plt.title('Image Dimensions: Width vs Height')\n",
        "plt.xlabel('Width (pixels)')\n",
        "plt.ylabel('Height (pixels)')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3. Image Metadata Analysis\n",
        "print(\"\\n=== Image Metadata Analysis ===\")\n",
        "\n",
        "def extract_exif_data(img_path):\n",
        "    \"\"\"Extract EXIF data from an image\"\"\"\n",
        "    try:\n",
        "        img = Image.open(img_path)\n",
        "        exif = {\n",
        "            PIL.ExifTags.TAGS[k]: v\n",
        "            for k, v in img._getexif().items()\n",
        "            if k in PIL.ExifTags.TAGS\n",
        "        } if img._getexif() else {}\n",
        "        return exif\n",
        "    except:\n",
        "        return {}\n",
        "\n",
        "# Sample a smaller subset for EXIF analysis (to save time)\n",
        "exif_sample_size = min(200, len(all_train_imgs))\n",
        "exif_sampled_imgs = random.sample(all_train_imgs, exif_sample_size)\n",
        "\n",
        "# Collect camera models\n",
        "camera_models = []\n",
        "for img_path in tqdm(exif_sampled_imgs, desc=\"Extracting EXIF data\"):\n",
        "    exif = extract_exif_data(img_path)\n",
        "    model = exif.get('Model', 'Unknown')\n",
        "    camera_models.append(model)\n",
        "\n",
        "# Count camera models\n",
        "camera_counts = Counter(camera_models)\n",
        "top_cameras = dict(camera_counts.most_common(10))\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=list(top_cameras.keys()), y=list(top_cameras.values()))\n",
        "plt.title('Top 10 Camera Models in Dataset')\n",
        "plt.xlabel('Camera Model')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 4. Image Quality and Statistical Analysis\n",
        "print(\"\\n=== Image Quality and Statistical Analysis ===\")\n",
        "\n",
        "def compute_image_statistics(img_path):\n",
        "    \"\"\"Compute basic statistical properties of an image\"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    # Basic statistics\n",
        "    mean = np.mean(img)\n",
        "    std = np.std(img)\n",
        "    median = np.median(img)\n",
        "    min_val = np.min(img)\n",
        "    max_val = np.max(img)\n",
        "    \n",
        "    # Compute entropy (measure of randomness)\n",
        "    histogram = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
        "    histogram = histogram / histogram.sum()\n",
        "    entropy = -np.sum(histogram * np.log2(histogram + 1e-7))\n",
        "    \n",
        "    return {\n",
        "        'mean': mean,\n",
        "        'std': std,\n",
        "        'median': median,\n",
        "        'min': min_val,\n",
        "        'max': max_val,\n",
        "        'entropy': entropy\n",
        "    }\n",
        "\n",
        "# Sample images from each category\n",
        "num_samples = min(100, len(cover_imgs))\n",
        "sampled_cover = random.sample(cover_imgs, num_samples)\n",
        "sampled_jmipod = random.sample(jmipod_imgs, num_samples)\n",
        "sampled_juniward = random.sample(juniward_imgs, num_samples)\n",
        "sampled_uerd = random.sample(uerd_imgs, num_samples)\n",
        "\n",
        "# Compute statistics for each category\n",
        "stats_cover = [compute_image_statistics(img) for img in tqdm(sampled_cover, desc=\"Cover stats\")]\n",
        "stats_cover = [s for s in stats_cover if s is not None]  # Remove None values\n",
        "\n",
        "stats_jmipod = [compute_image_statistics(img) for img in tqdm(sampled_jmipod, desc=\"JMiPOD stats\")]\n",
        "stats_jmipod = [s for s in stats_jmipod if s is not None]\n",
        "\n",
        "stats_juniward = [compute_image_statistics(img) for img in tqdm(sampled_juniward, desc=\"JUNIWARD stats\")]\n",
        "stats_juniward = [s for s in stats_juniward if s is not None]\n",
        "\n",
        "stats_uerd = [compute_image_statistics(img) for img in tqdm(sampled_uerd, desc=\"UERD stats\")]\n",
        "stats_uerd = [s for s in stats_uerd if s is not None]\n",
        "\n",
        "# Convert to DataFrame for easier analysis\n",
        "df_cover = pd.DataFrame(stats_cover)\n",
        "df_cover['type'] = 'Cover'\n",
        "\n",
        "df_jmipod = pd.DataFrame(stats_jmipod)\n",
        "df_jmipod['type'] = 'JMiPOD'\n",
        "\n",
        "df_juniward = pd.DataFrame(stats_juniward)\n",
        "df_juniward['type'] = 'JUNIWARD'\n",
        "\n",
        "df_uerd = pd.DataFrame(stats_uerd)\n",
        "df_uerd['type'] = 'UERD'\n",
        "\n",
        "# Combine all stats\n",
        "df_all_stats = pd.concat([df_cover, df_jmipod, df_juniward, df_uerd])\n",
        "\n",
        "# Visualize statistics across categories\n",
        "plt.figure(figsize=(20, 15))\n",
        "\n",
        "metrics = ['mean', 'std', 'entropy', 'median', 'min', 'max']\n",
        "for i, metric in enumerate(metrics):\n",
        "    plt.subplot(3, 2, i+1)\n",
        "    sns.boxplot(x='type', y=metric, data=df_all_stats)\n",
        "    plt.title(f'Distribution of {metric.capitalize()} by Image Type')\n",
        "    plt.xlabel('Image Type')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistical tests to compare distributions\n",
        "print(\"\\n=== Statistical Tests: Cover vs Stego ===\")\n",
        "for metric in metrics:\n",
        "    print(f\"\\nComparing {metric} distributions:\")\n",
        "    \n",
        "    # KS test for Cover vs each stego method\n",
        "    ks_jmipod = ks_2samp(df_cover[metric], df_jmipod[metric])\n",
        "    ks_juniward = ks_2samp(df_cover[metric], df_juniward[metric])\n",
        "    ks_uerd = ks_2samp(df_cover[metric], df_uerd[metric])\n",
        "    \n",
        "    print(f\"Cover vs JMiPOD: KS statistic={ks_jmipod.statistic:.4f}, p-value={ks_jmipod.pvalue:.6f}\")\n",
        "    print(f\"Cover vs JUNIWARD: KS statistic={ks_juniward.statistic:.4f}, p-value={ks_juniward.pvalue:.6f}\")\n",
        "    print(f\"Cover vs UERD: KS statistic={ks_uerd.statistic:.4f}, p-value={ks_uerd.pvalue:.6f}\")\n",
        "\n",
        "# 5. Pixel Value Distribution Analysis\n",
        "print(\"\\n=== Pixel Value Distribution Analysis ===\")\n",
        "\n",
        "def compute_histogram(img_path):\n",
        "    \"\"\"Compute histogram of pixel values\"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    hist = cv2.calcHist([img], [0], None, [256], [0, 256])\n",
        "    return hist.flatten()\n",
        "\n",
        "# Sample smaller set for histogram analysis\n",
        "hist_sample_size = 20\n",
        "hist_cover = [compute_histogram(img) for img in random.sample(cover_imgs, hist_sample_size)]\n",
        "hist_cover = [h for h in hist_cover if h is not None]\n",
        "\n",
        "hist_jmipod = [compute_histogram(img) for img in random.sample(jmipod_imgs, hist_sample_size)]\n",
        "hist_jmipod = [h for h in hist_jmipod if h is not None]\n",
        "\n",
        "hist_juniward = [compute_histogram(img) for img in random.sample(juniward_imgs, hist_sample_size)]\n",
        "hist_juniward = [h for h in hist_juniward if h is not None]\n",
        "\n",
        "hist_uerd = [compute_histogram(img) for img in random.sample(uerd_imgs, hist_sample_size)]\n",
        "hist_uerd = [h for h in hist_uerd if h is not None]\n",
        "\n",
        "# Average histograms\n",
        "avg_hist_cover = np.mean(hist_cover, axis=0)\n",
        "avg_hist_jmipod = np.mean(hist_jmipod, axis=0)\n",
        "avg_hist_juniward = np.mean(hist_juniward, axis=0)\n",
        "avg_hist_uerd = np.mean(hist_uerd, axis=0)\n",
        "\n",
        "# Plot average histograms\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(avg_hist_cover, color='blue')\n",
        "plt.title('Average Histogram: Cover Images')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(avg_hist_jmipod, color='red')\n",
        "plt.title('Average Histogram: JMiPOD Images')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(avg_hist_juniward, color='green')\n",
        "plt.title('Average Histogram: JUNIWARD Images')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(avg_hist_uerd, color='purple')\n",
        "plt.title('Average Histogram: UERD Images')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plot histogram differences\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(avg_hist_jmipod - avg_hist_cover)\n",
        "plt.title('Histogram Difference: JMiPOD - Cover')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Difference')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(avg_hist_juniward - avg_hist_cover)\n",
        "plt.title('Histogram Difference: JUNIWARD - Cover')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Difference')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(avg_hist_uerd - avg_hist_cover)\n",
        "plt.title('Histogram Difference: UERD - Cover')\n",
        "plt.xlabel('Pixel Value')\n",
        "plt.ylabel('Difference')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 6. Noise Analysis\n",
        "print(\"\\n=== Noise Residual Analysis ===\")\n",
        "\n",
        "def compute_noise_residual(img_path):\n",
        "    \"\"\"Compute noise residual from an image using a denoising filter\"\"\"\n",
        "    img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        return None\n",
        "    \n",
        "    # Apply denoising filter\n",
        "    denoised = cv2.fastNlMeansDenoising(img, None, 10, 7, 21)\n",
        "    \n",
        "    # Calculate residual (difference between original and denoised)\n",
        "    residual = img.astype(np.float32) - denoised.astype(np.float32)\n",
        "    \n",
        "    # Compute statistics on the residual\n",
        "    mean = np.mean(residual)\n",
        "    std = np.std(residual)\n",
        "    entropy = -np.sum(np.histogram(residual, bins=100, density=True)[0] * \n",
        "                       np.log2(np.histogram(residual, bins=100, density=True)[0] + 1e-10))\n",
        "    \n",
        "    return {\n",
        "        'mean': mean,\n",
        "        'std': std,\n",
        "        'entropy': entropy\n",
        "    }\n",
        "\n",
        "# Sample images for noise analysis\n",
        "noise_sample_size = min(50, len(cover_imgs))\n",
        "sampled_cover_noise = random.sample(cover_imgs, noise_sample_size)\n",
        "sampled_jmipod_noise = random.sample(jmipod_imgs, noise_sample_size)\n",
        "sampled_juniward_noise = random.sample(juniward_imgs, noise_sample_size)\n",
        "sampled_uerd_noise = random.sample(uerd_imgs, noise_sample_size)\n",
        "\n",
        "# Compute noise residuals\n",
        "noise_cover = [compute_noise_residual(img) for img in tqdm(sampled_cover_noise, desc=\"Cover noise\")]\n",
        "noise_cover = [n for n in noise_cover if n is not None]\n",
        "\n",
        "noise_jmipod = [compute_noise_residual(img) for img in tqdm(sampled_jmipod_noise, desc=\"JMiPOD noise\")]\n",
        "noise_jmipod = [n for n in noise_jmipod if n is not None]\n",
        "\n",
        "noise_juniward = [compute_noise_residual(img) for img in tqdm(sampled_juniward_noise, desc=\"JUNIWARD noise\")]\n",
        "noise_juniward = [n for n in noise_juniward if n is not None]\n",
        "\n",
        "noise_uerd = [compute_noise_residual(img) for img in tqdm(sampled_uerd_noise, desc=\"UERD noise\")]\n",
        "noise_uerd = [n for n in noise_uerd if n is not None]\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_noise_cover = pd.DataFrame(noise_cover)\n",
        "df_noise_cover['type'] = 'Cover'\n",
        "\n",
        "df_noise_jmipod = pd.DataFrame(noise_jmipod)\n",
        "df_noise_jmipod['type'] = 'JMiPOD'\n",
        "\n",
        "df_noise_juniward = pd.DataFrame(noise_juniward)\n",
        "df_noise_juniward['type'] = 'JUNIWARD'\n",
        "\n",
        "df_noise_uerd = pd.DataFrame(noise_uerd)\n",
        "df_noise_uerd['type'] = 'UERD'\n",
        "\n",
        "# Combine all noise stats\n",
        "df_all_noise = pd.concat([df_noise_cover, df_noise_jmipod, df_noise_juniward, df_noise_uerd])\n",
        "\n",
        "# Visualize noise statistics\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "noise_metrics = ['mean', 'std', 'entropy']\n",
        "for i, metric in enumerate(noise_metrics):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    sns.boxplot(x='type', y=metric, data=df_all_noise)\n",
        "    plt.title(f'Noise Residual {metric.capitalize()} by Image Type')\n",
        "    plt.xlabel('Image Type')\n",
        "    plt.ylabel(metric.capitalize())\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7. Visual Comparison of Cover and Stego Pairs\n",
        "print(\"\\n=== Visual Comparison of Cover-Stego Pairs ===\")\n",
        "\n",
        "def visualize_stego_differences(cover_path, stego_path, amplification=10):\n",
        "    \"\"\"Visualize differences between cover and stego image pairs\"\"\"\n",
        "    cover_name = os.path.basename(cover_path)\n",
        "    stego_name = os.path.basename(stego_path)\n",
        "    \n",
        "    cover = cv2.imread(cover_path)\n",
        "    stego = cv2.imread(stego_path)\n",
        "    \n",
        "    if cover is None or stego is None:\n",
        "        return None\n",
        "    \n",
        "    # Calculate difference and amplify it for visualization\n",
        "    diff = cv2.absdiff(cover, stego)\n",
        "    diff_amplified = cv2.convertScaleAbs(diff, alpha=amplification)\n",
        "    \n",
        "    # Calculate noise residuals\n",
        "    cover_gray = cv2.cvtColor(cover, cv2.COLOR_BGR2GRAY)\n",
        "    stego_gray = cv2.cvtColor(stego, cv2.COLOR_BGR2GRAY)\n",
        "    \n",
        "    cover_denoised = cv2.fastNlMeansDenoising(cover_gray, None, 10, 7, 21)\n",
        "    stego_denoised = cv2.fastNlMeansDenoising(stego_gray, None, 10, 7, 21)\n",
        "    \n",
        "    cover_residual = cover_gray - cover_denoised\n",
        "    stego_residual = stego_gray - stego_denoised\n",
        "    \n",
        "    residual_diff = cv2.absdiff(stego_residual, cover_residual)\n",
        "    residual_diff_amplified = cv2.convertScaleAbs(residual_diff, alpha=amplification)\n",
        "    \n",
        "    return {\n",
        "        'cover': cover,\n",
        "        'stego': stego,\n",
        "        'diff': diff,\n",
        "        'diff_amplified': diff_amplified,\n",
        "        'cover_residual': cover_residual,\n",
        "        'stego_residual': stego_residual,\n",
        "        'residual_diff': residual_diff,\n",
        "        'residual_diff_amplified': residual_diff_amplified,\n",
        "        'cover_name': cover_name,\n",
        "        'stego_name': stego_name\n",
        "    }\n",
        "\n",
        "# Select sample pairs\n",
        "num_pairs = 3\n",
        "cover_samples = random.sample(cover_imgs, num_pairs)\n",
        "\n",
        "# Create pairs\n",
        "jmipod_pairs = [(cover, cover.replace('Cover', 'JMiPOD')) for cover in cover_samples]\n",
        "juniward_pairs = [(cover, cover.replace('Cover', 'JUNIWARD')) for cover in cover_samples]\n",
        "uerd_pairs = [(cover, cover.replace('Cover', 'UERD')) for cover in cover_samples]\n",
        "\n",
        "# Visualize JMiPOD pairs\n",
        "for cover_path, stego_path in jmipod_pairs:\n",
        "    result = visualize_stego_differences(cover_path, stego_path)\n",
        "    if result is None:\n",
        "        continue\n",
        "        \n",
        "    plt.figure(figsize=(20, 10))\n",
        "    \n",
        "    plt.subplot(2, 4, 1)\n",
        "    plt.imshow(cv2.cvtColor(result['cover'], cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'Cover Image: {result[\"cover_name\"]}')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 2)\n",
        "    plt.imshow(cv2.cvtColor(result['stego'], cv2.COLOR_BGR2RGB))\n",
        "    plt.title(f'JMiPOD Stego: {result[\"stego_name\"]}')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 3)\n",
        "    plt.imshow(cv2.cvtColor(result['diff'], cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Difference (Unscaled)')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 4)\n",
        "    plt.imshow(cv2.cvtColor(result['diff_amplified'], cv2.COLOR_BGR2RGB))\n",
        "    plt.title('Difference (Amplified 10x)')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 5)\n",
        "    plt.imshow(result['cover_residual'], cmap='gray')\n",
        "    plt.title('Cover Noise Residual')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 6)\n",
        "    plt.imshow(result['stego_residual'], cmap='gray')\n",
        "    plt.title('Stego Noise Residual')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 7)\n",
        "    plt.imshow(result['residual_diff'], cmap='hot')\n",
        "    plt.title('Residual Difference')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.subplot(2, 4, 8)\n",
        "    plt.imshow(result['residual_diff_amplified'], cmap='hot')\n",
        "    plt.title('Residual Difference (Amplified 10x)')\n",
        "    plt.axis('off')\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
